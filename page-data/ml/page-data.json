{"componentChunkName":"component---src-templates-blog-post-js","path":"/ml","result":{"data":{"markdownRemark":{"rawMarkdownBody":"\n# Machine Learning and Data Science\n\nIn lecture, we talked about how **Machine Learning** just boils down to making predictions about the world, given adequete data. We also learned about a variety of different techniques for the machine learning process, namely data pre-processing and splitting data into a training/test split.\n\nSlides from lecture are available [here](https://kirubarajan.nyc3.digitaloceanspaces.com/spring2020/Machine%20Learning%20I.pdf).\n\n## Analyzing Cereal\n\nIn lecture, we took a look at the [Cereal Dataset](https://www.kaggle.com/crawford/80-cereals) from Kaggle.\n\n### Working With Files\n\nWe used the following script to load the `\"cereal.csv\"` file:\n\n```python\nimport pickle\n\ndef get_points(file_path):\n    with open(file_path) as dataset:\n        points = dict()\n\n        for line in dataset.readlines()[1:]:\n            fields = line.split(\",\")\n            name, calories, sugar, rating = fields[0], float(fields[3]), float(fields[9]), float(fields[-1].strip())\n            points[name] = calories, sugar, rating\n\n    return points\n\ndef save_points(points, file_path):\n    with open(file_path, \"wb\") as points_file:\n        pickle.dump(points, points_file)\n\ndef load_points(file_path):\n    with open(file_path, \"rb\") as points_file:\n        points = pickle.load(points_file)\n        return points\n\npoints = get_points(\"cereal.csv\")\nsave_points(points, \"dataset.something\")\nprint(load_points(\"dataset.something\"))\n```\n\nThis script opens the UTF-8 encoded `.csv` file, and reads in the relevant fields of `name`, `sugar`, `calories`, and `rating` before returning a dictionary of the different data points.\n\nThe `save_points` and `load_points` functions allow us to _serialize_ a Python object into a file that is stored locally using the first-party `pickle` package. This is convinient, since we don't need to re-parse the file, and instead it is directly loaded into Python's \"memory\".\n\n### Visualizing Data\n\nIn this script, we `import`-ed our previous `get_points` function from the other module, and we used a third-party library named `matplotlib` to plot the points graphically:\n\n```python\nfrom data import get_points\nimport matplotlib.pyplot as plt\n\npoints = get_points(\"cereal.csv\").items()\nfig, ax = plt.subplots()\n\n# calories\nx = [info[1] for name, info in points]\n# rating\ny = [info[2] for name, info in points]\n\nax.scatter(x, y)\n\n# annotating with name\nfor i, (name, info) in enumerate(points):\n    ax.annotate(name[:5], (x[i], y[i]))\n\nplt.show()\n```\n\nThe script plots either calories or sugar on the x-axis and the cereal's rating on the y-axis. We also annotate each point with the cereal's name to make our graph more interpretable.\n\n### Training a Machine Learning Model\n\nFinally, we trained a machine learning model named `KNeighborsRegressor` to predict the rating of a cereal, given it's sugar and calories as **features**. The model is a variant of the K-Nearest Neighbours classifier discussed in class. However, the model performs a _regression_ task of predicting a continuous value, rather than a discrete one.\n\nWe first `import` the data points, partition the data into a training and testing splits, and then train the classifier:\n\n```python\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom data import get_points\nimport numpy as np\n\n# getting data\ndata = list(get_points(\"cereal.csv\").items())\nsplit = (len(data) // 10) * 8\n\n# splitting data\ntraining, test = data[:split], data[split:]\n\n# formatting train data\ntraining_data = np.array([(features[0], features[1]) for name, features in training]).astype(np.float64)\ntraining_labels = np.array([features[2] for name, features in training]).astype(np.float64)\n\n# formatting test data\ntest_data = np.array([(features[0], features[1]) for name, features in training]).astype(np.float64)\ntest_labels = np.array([features[2] for name, features in training])\n\n# making predictions\nknn = KNeighborsRegressor(n_neighbors=3)\nknn.fit(training_data, training_labels)\n\n# scoring predictions\nprint(knn.predict(test_data[:3]))\nprint(knn.score(test_data, test_labels))\n```\n\nOur final two lines print some example predictions, followed by the model's evaluation score.\n\n## Conclusion\n\nThere are many different third-party tools and frameworks that make machine learning easy in Python. We discussed in class how they use [Cython](https://cython.org/) to speed up the performance of the code, and this will become more apparent in the following week's lectures, when we look into Natural Language Processing and Deep Learning!\n\n## References\n\n1. Pickling (Official)\n2. Read/Writing to Files (Official)\n3. Sci-Kit Learn\n4. Matplotlib\n","html":"<h1>Machine Learning and Data Science</h1>\n<p>In lecture, we talked about how <strong>Machine Learning</strong> just boils down to making predictions about the world, given adequete data. We also learned about a variety of different techniques for the machine learning process, namely data pre-processing and splitting data into a training/test split.</p>\n<p>Slides from lecture are available <a href=\"https://kirubarajan.nyc3.digitaloceanspaces.com/spring2020/Machine%20Learning%20I.pdf\">here</a>.</p>\n<h2>Analyzing Cereal</h2>\n<p>In lecture, we took a look at the <a href=\"https://www.kaggle.com/crawford/80-cereals\">Cereal Dataset</a> from Kaggle.</p>\n<h3>Working With Files</h3>\n<p>We used the following script to load the <code class=\"language-text\">&quot;cereal.csv&quot;</code> file:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pickle\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_points</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> dataset<span class=\"token punctuation\">:</span>\n        points <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> dataset<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            fields <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">)</span>\n            name<span class=\"token punctuation\">,</span> calories<span class=\"token punctuation\">,</span> sugar<span class=\"token punctuation\">,</span> rating <span class=\"token operator\">=</span> fields<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>fields<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>fields<span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>fields<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            points<span class=\"token punctuation\">[</span>name<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> calories<span class=\"token punctuation\">,</span> sugar<span class=\"token punctuation\">,</span> rating\n\n    <span class=\"token keyword\">return</span> points\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">save_points</span><span class=\"token punctuation\">(</span>points<span class=\"token punctuation\">,</span> file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">\"wb\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> points_file<span class=\"token punctuation\">:</span>\n        pickle<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>points<span class=\"token punctuation\">,</span> points_file<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">load_points</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">\"rb\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> points_file<span class=\"token punctuation\">:</span>\n        points <span class=\"token operator\">=</span> pickle<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>points_file<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> points\n\npoints <span class=\"token operator\">=</span> get_points<span class=\"token punctuation\">(</span><span class=\"token string\">\"cereal.csv\"</span><span class=\"token punctuation\">)</span>\nsave_points<span class=\"token punctuation\">(</span>points<span class=\"token punctuation\">,</span> <span class=\"token string\">\"dataset.something\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>load_points<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset.something\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This script opens the UTF-8 encoded <code class=\"language-text\">.csv</code> file, and reads in the relevant fields of <code class=\"language-text\">name</code>, <code class=\"language-text\">sugar</code>, <code class=\"language-text\">calories</code>, and <code class=\"language-text\">rating</code> before returning a dictionary of the different data points.</p>\n<p>The <code class=\"language-text\">save_points</code> and <code class=\"language-text\">load_points</code> functions allow us to <em>serialize</em> a Python object into a file that is stored locally using the first-party <code class=\"language-text\">pickle</code> package. This is convinient, since we don't need to re-parse the file, and instead it is directly loaded into Python's \"memory\".</p>\n<h3>Visualizing Data</h3>\n<p>In this script, we <code class=\"language-text\">import</code>-ed our previous <code class=\"language-text\">get_points</code> function from the other module, and we used a third-party library named <code class=\"language-text\">matplotlib</code> to plot the points graphically:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> data <span class=\"token keyword\">import</span> get_points\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\npoints <span class=\"token operator\">=</span> get_points<span class=\"token punctuation\">(</span><span class=\"token string\">\"cereal.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfig<span class=\"token punctuation\">,</span> ax <span class=\"token operator\">=</span> plt<span class=\"token punctuation\">.</span>subplots<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># calories</span>\nx <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>info<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> info <span class=\"token keyword\">in</span> points<span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># rating</span>\ny <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>info<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> info <span class=\"token keyword\">in</span> points<span class=\"token punctuation\">]</span>\n\nax<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># annotating with name</span>\n<span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">,</span> info<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>points<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    ax<span class=\"token punctuation\">.</span>annotate<span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>The script plots either calories or sugar on the x-axis and the cereal's rating on the y-axis. We also annotate each point with the cereal's name to make our graph more interpretable.</p>\n<h3>Training a Machine Learning Model</h3>\n<p>Finally, we trained a machine learning model named <code class=\"language-text\">KNeighborsRegressor</code> to predict the rating of a cereal, given it's sugar and calories as <strong>features</strong>. The model is a variant of the K-Nearest Neighbours classifier discussed in class. However, the model performs a <em>regression</em> task of predicting a continuous value, rather than a discrete one.</p>\n<p>We first <code class=\"language-text\">import</code> the data points, partition the data into a training and testing splits, and then train the classifier:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>neighbors <span class=\"token keyword\">import</span> KNeighborsRegressor\n<span class=\"token keyword\">from</span> data <span class=\"token keyword\">import</span> get_points\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token comment\"># getting data</span>\ndata <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>get_points<span class=\"token punctuation\">(</span><span class=\"token string\">\"cereal.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nsplit <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">8</span>\n\n<span class=\"token comment\"># splitting data</span>\ntraining<span class=\"token punctuation\">,</span> test <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># formatting train data</span>\ntraining_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> features<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> features <span class=\"token keyword\">in</span> training<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float64<span class=\"token punctuation\">)</span>\ntraining_labels <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>features<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> features <span class=\"token keyword\">in</span> training<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float64<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># formatting test data</span>\ntest_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> features<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> features <span class=\"token keyword\">in</span> training<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float64<span class=\"token punctuation\">)</span>\ntest_labels <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>features<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> features <span class=\"token keyword\">in</span> training<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># making predictions</span>\nknn <span class=\"token operator\">=</span> KNeighborsRegressor<span class=\"token punctuation\">(</span>n_neighbors<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\nknn<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>training_data<span class=\"token punctuation\">,</span> training_labels<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># scoring predictions</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>knn<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>knn<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">,</span> test_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Our final two lines print some example predictions, followed by the model's evaluation score.</p>\n<h2>Conclusion</h2>\n<p>There are many different third-party tools and frameworks that make machine learning easy in Python. We discussed in class how they use <a href=\"https://cython.org/\">Cython</a> to speed up the performance of the code, and this will become more apparent in the following week's lectures, when we look into Natural Language Processing and Deep Learning!</p>\n<h2>References</h2>\n<ol>\n<li>Pickling (Official)</li>\n<li>Read/Writing to Files (Official)</li>\n<li>Sci-Kit Learn</li>\n<li>Matplotlib</li>\n</ol>"}},"pageContext":{"pathSlug":"/ml"}},"staticQueryHashes":[]}